[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EPPS 6302 Methods of Data Collection & Production",
    "section": "",
    "text": "Hello! My name is Nakir, and I am a PhD candidate in Geospatial Information Sciences at The University of Texas at Dallas.\nCurrently, I am working on cassava identification using UAV imagery.\nContact:\nüìß md.nakir.ahmed.09@gmail.com\nüîó LinkedIn"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "assignment04_Nakir.html#assignment-04-web-scraping-cleaning",
    "href": "assignment04_Nakir.html#assignment-04-web-scraping-cleaning",
    "title": "Assignment 04",
    "section": "Assignment 04 ‚Äì Web Scraping & Cleaning",
    "text": "Assignment 04 ‚Äì Web Scraping & Cleaning"
  },
  {
    "objectID": "assignment04_Nakir.html",
    "href": "assignment04_Nakir.html",
    "title": "Assignment 04",
    "section": "",
    "text": "Scrape a Wiki table (Life Expectancy) and clean it\n\n############################################################\n## Assignment 04\n############################################################\n\n# 1. Libraries\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.2     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.4     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(rvest)\n\n\nAttaching package: 'rvest'\n\nThe following object is masked from 'package:readr':\n\n    guess_encoding\n\nlibrary(stringr)\n\n# 2. Target Page\nurl &lt;- \"https://en.wikipedia.org/wiki/List_of_countries_by_life_expectancy\"\npage &lt;- read_html(url)\n\n# 3. Grab all wikitables on the page\nall_tables &lt;- page |&gt;\n  html_elements(\"table.wikitable\") |&gt;\n  html_table(fill = TRUE)\n\nif (length(all_tables) == 0) stop(\"No .wikitable tables found.\")\n\n# 4. Helper functions\nnorm_names &lt;- function(x) {\n  x |&gt;\n    str_to_lower() |&gt;\n    str_replace_all(\"\\\\s+\", \"_\") |&gt;\n    str_replace_all(\"[^a-z0-9_]\", \"\")\n}\n\nscore_table &lt;- function(df) {\n  nms &lt;- norm_names(names(df))\n  has_country &lt;- any(str_detect(nms, \"country|territor|area|location|nation|state\"))\n  has_overall &lt;- any(str_detect(nms, \"overall|both|total|life_expectancy(.*)birth$|^life_expectancy$\"))\n  has_male &lt;- any(str_detect(nms, \"male\"))\n  has_female &lt;- any(str_detect(nms, \"female\"))\n  as.integer(has_country) + as.integer(has_overall) + as.integer(has_male) + as.integer(has_female)\n}\n\nstrip_notes &lt;- function(x) str_replace_all(x, \"\\\\[[^\\\\]]*\\\\]\", \"\") |&gt;\n  trimws()\nto_numeric &lt;- function(x) suppressWarnings(as.numeric(str_replace_all(x, \"[^0-9.]\", \"\")))\n\n# 5. Pick the best table automatically\nscores &lt;- purrr::map_int(all_tables, score_table)\nbest_idx &lt;- which.max(scores)\nif (scores[best_idx] == 0) stop(\"No table with required columns found.\")\nlife_df_raw &lt;- all_tables[[best_idx]]\n\ncat(\"Using table index:\", best_idx, \"out of\", length(all_tables), \"\\n\")\n\nUsing table index: 6 out of 6 \n\n# 6. Standardize column names\nnms &lt;- norm_names(names(life_df_raw))\nnames(life_df_raw) &lt;- nms\n\n# Locate core columns\ncol_country &lt;- names(life_df_raw)[str_detect(nms, \"country|territor|area|location|nation|state\")][1]\ncol_overall &lt;- names(life_df_raw)[str_detect(nms, \"overall|both|total|life_expectancy(.*)birth$|^life_expectancy$\")][1]\ncol_male &lt;- names(life_df_raw)[str_detect(nms, \"male\")][1]\ncol_female &lt;- names(life_df_raw)[str_detect(nms, \"female\")][1]\n\n# 7. Build clean dataset (no Rank/Date)\nlife_df_clean &lt;- tibble(\n  Country = strip_notes(as.character(life_df_raw[[col_country]])),\n  Overall_Years = to_numeric(life_df_raw[[col_overall]]),\n  Male_Years = to_numeric(life_df_raw[[col_male]]),\n  Female_Years = to_numeric(life_df_raw[[col_female]])\n) |&gt;\n  filter(!(is.na(Overall_Years) & is.na(Male_Years) & is.na(Female_Years))) |&gt;\n  arrange(Country)\n\n# 8. Preview\ncat(\"\\nClean dataset preview (top 10 rows):\\n\")\n\n\nClean dataset preview (top 10 rows):\n\nprint(head(life_df_clean, 10))\n\n# A tibble: 10 √ó 4\n   Country    Overall_Years Male_Years Female_Years\n   &lt;chr&gt;              &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 Argentina           75.4       72.2         78.6\n 2 Austria             81.1       78.8         83.5\n 3 Belgium             81.8       79.6         83.9\n 4 Brazil              72.8       69.6         76  \n 5 Bulgaria            74.3       70.8         78.1\n 6 Chile               81.2       78.5         84  \n 7 China               78.2       75.5         81.2\n 8 Colombia            76.9       73.8         80.1\n 9 Costa Rica          80.9       78.3         83.5\n10 Croatia             77.7       74.6         80.8\n\ncat(\"\\nStructure:\\n\")\n\n\nStructure:\n\nstr(life_df_clean)\n\ntibble [38 √ó 4] (S3: tbl_df/tbl/data.frame)\n $ Country      : chr [1:38] \"Argentina\" \"Austria\" \"Belgium\" \"Brazil\" ...\n $ Overall_Years: num [1:38] 75.4 81.1 81.8 72.8 74.3 81.2 78.2 76.9 80.9 77.7 ...\n $ Male_Years   : num [1:38] 72.2 78.8 79.6 69.6 70.8 78.5 75.5 73.8 78.3 74.6 ...\n $ Female_Years : num [1:38] 78.6 83.5 83.9 76 78.1 84 81.2 80.1 83.5 80.8 ...\n\n# 9. Save to CSV\nwrite.csv(life_df_clean, \"life_expectancy_tidy.csv\", row.names = FALSE)\ncat(\"\\nSaved as 'life_expectancy_tidy.csv' in your working directory.\\n\")\n\n\nSaved as 'life_expectancy_tidy.csv' in your working directory."
  },
  {
    "objectID": "assignment06_Nakir.html",
    "href": "assignment06_Nakir.html",
    "title": "Assignment 06",
    "section": "",
    "text": "Load Libraries and Data\n\nlibrary(quanteda)\n\nPackage version: 4.2.0\nUnicode version: 15.1\nICU version: 74.1\n\n\nParallel computing: 8 of 8 threads used.\n\n\nSee https://quanteda.io for tutorials and examples.\n\nlibrary(quanteda.textmodels)\nlibrary(quanteda.textplots)\nlibrary(readr)\nlibrary(ggplot2)\n\nsummit &lt;- read_csv(\"https://raw.githubusercontent.com/datageneration/datamethods/master/textanalytics/summit_11162021.csv\")\n\nRows: 14520 Columns: 90\n\n\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr  (50): screen_name, text, source, reply_to_screen_name, hashtags, symbol...\ndbl  (26): user_id, status_id, display_text_width, reply_to_status_id, reply...\nlgl  (10): is_quote, is_retweet, quote_count, reply_count, ext_media_type, q...\ndttm  (4): created_at, quoted_created_at, retweet_created_at, account_create...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsum_twt &lt;- summit$text\ntoks &lt;- tokens(sum_twt)\nsumtwtdfm &lt;- dfm(toks)\n\n\n\nLatent Semantic Analysis\n\nsum_lsa &lt;- textmodel_lsa(sumtwtdfm)\nsummary(sum_lsa)\n\n                Length    Class     Mode   \nsk                     10 -none-    numeric\ndocs               145200 -none-    numeric\nfeatures           159930 -none-    numeric\nmatrix_low_rank 232218360 -none-    numeric\ndata            232218360 dgCMatrix S4     \n\n\n\n\nDocument-feature matrix and top hashtags\n\ntweet_dfm &lt;- tokens(sum_twt, remove_punct = TRUE) %&gt;%\n  dfm()\ntag_dfm &lt;- dfm_select(tweet_dfm, pattern = \"#*\")\ntoptag &lt;- names(topfeatures(tag_dfm, 50))\nhead(toptag, 10)\n\n [1] \"#china\"       \"#biden\"       \"#xijinping\"   \"#joebiden\"    \"#america\"    \n [6] \"#americans\"   \"#coronavirus\" \"#fentanyl\"    \"#xi\"          \"#us\"         \n\n\n\n\nNetwork Plot: Hashtags\n\ntag_fcm &lt;- fcm(tag_dfm)\ntopgat_fcm &lt;- fcm_select(tag_fcm, pattern = toptag)\ntextplot_network(topgat_fcm, min_freq = 50, edge_alpha = 0.8, edge_size = 5)\n\n\n\n\n\n\n\n\n\n\nNetwork Plot: Users\n\nuser_dfm &lt;- dfm_select(tweet_dfm, pattern = \"@*\")\ntopuser &lt;- names(topfeatures(user_dfm, 50))\nuser_fcm &lt;- fcm(user_dfm)\nuser_fcm &lt;- fcm_select(user_fcm, pattern = topuser)\ntextplot_network(user_fcm, min_freq = 20, edge_color = \"firebrick\", edge_alpha = 0.8, edge_size = 5)\n\n\n\n\n\n\n\n\n\n\nWordcloud: Early Inaugural Speeches\n\ndfm_inaug &lt;- corpus_subset(data_corpus_inaugural, Year &lt;= 1826) %&gt;% \n  tokens(remove_punct = TRUE) %&gt;% \n  tokens_remove(stopwords(\"english\")) %&gt;% \n  dfm() %&gt;% \n  dfm_trim(min_termfreq = 10, verbose = FALSE)\nset.seed(100)\ntextplot_wordcloud(dfm_inaug)\n\n\n\n\n\n\n\n\n\n\nComparison Wordcloud by Presidents\n\ncorpus_subset(data_corpus_inaugural, \n              President %in% c(\"Biden\",\"Trump\", \"Obama\", \"Bush\")) %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"english\")) %&gt;%\n  dfm() %&gt;%\n  dfm_group(groups = President) %&gt;%\n  dfm_trim(min_termfreq = 5, verbose = FALSE) %&gt;%\n  textplot_wordcloud(comparison = TRUE)\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\njobs could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nborders could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\npresident could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nnations could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nworkers could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\ntogether could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nsuccess could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nthank could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\npower could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nunited could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nfollow could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nlonger could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\ndone could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nland could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\ngovernment could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nwashington could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nnational could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nsmall could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nnation's could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\neven could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nmade could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nearth could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nday could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nstates could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nalways could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nbless could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nmeasure could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nstrength could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nspeak could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nprogress could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nexample could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\ndream could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\npoverty could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nconfidence could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nnation could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\ngive could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nrestore could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nthink could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nmaking could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\naccept could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nchief could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nready could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nthroughout could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\ninterests could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\ndifferent could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\npolitics could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nschools could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\npeaceful could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nhome could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nmothers could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nwatching could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\ntolerance could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nprotect could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nsomething could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nresponsibility could not be fit on page. It will not be plotted.\n\n\n\n\n\n\n\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nchallenges could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nremember could not be fit on page. It will not be plotted.\n\n\n\n\nKeywords-in-Context (KWIC) and X-Ray Plots\n\ndata_corpus_inaugural_subset &lt;- corpus_subset(data_corpus_inaugural, Year &gt; 1949)\nkwic(tokens(data_corpus_inaugural_subset), pattern = \"american\") %&gt;% textplot_xray()\n\n\n\n\n\n\n\nkwic(tokens(data_corpus_inaugural_subset), pattern = \"trade\") %&gt;% textplot_xray()\n\n\n\n\n\n\n\ntokens_inaugural &lt;- tokens(data_corpus_inaugural_subset)\ntextplot_xray(\n  kwic(tokens_inaugural, pattern = \"american\"),\n  kwic(tokens_inaugural, pattern = \"people\"),\n  kwic(tokens_inaugural, pattern = \"trade\")\n)\n\n\n\n\n\n\n\n\n\n\n\n3. Compare Biden-Xi Summit Tweets and US Presidential Inaugural Speeches\nThe Biden-Xi summit tweets largely focus on geopolitical tensions, diplomacy, and U.S.‚ÄìChina relations, with frequent use of terms like ‚ÄúBiden,‚Äù ‚ÄúXi,‚Äù ‚ÄúChina,‚Äù and hashtags such as #uschina and #summit. The language is informal, immediate, and often emotionally charged, reflecting real-time public reaction.\nIn contrast, U.S. presidential inaugural speeches are formal, structured reflections of national values and political priorities. While early speeches emphasized unity, liberty, and the Constitution, modern ones address broader issues like security, economy, and climate change. Despite evolving language and tone, recurring themes like democracy, nationhood, and the American people persist. Together, the datasets illustrate how public discourse and presidential rhetoric both reflect and shape national identity over time.\n\n\n\n4. What is Wordfish?\nWordfish is an unsupervised text scaling method used to estimate the position of documents (like political speeches or tweets) along a single latent dimension, such as ideology. It analyzes word frequencies to place texts on a scale without needing predefined labels.\nIn R, it‚Äôs implemented via textmodel_wordfish() in the quanteda.textmodels package and outputs each document‚Äôs position (theta) and word influence (beta) to help interpret the underlying topic or stance."
  }
]